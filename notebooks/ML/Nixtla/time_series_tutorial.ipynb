{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Nixtla Tutorial\n",
    "\n",
    "The Flash team is excited to share with you a small tutorial on Nixtla.\n",
    "Before jumping into this tutorial, we recommend giving a look to this [README](README.md) in order to get more familiar with Nixtla and its pros/cons ! \n",
    "\n",
    "Now that’s being said, let’s dig into a small example where we will use the M4 competition hourly dataset to forecast the next 24 next hours.\n",
    "\n",
    "To do so we'll explore the following features in Nixtla:\n",
    "\n",
    "1. Define Statistical models using the `StatsForecast` Nixtla package,\n",
    "2. Evaluate the model's performance using Cross Validation,\n",
    "3. Implement ML models (ex. LGBM) using the `MLForecast` Nixtla package\n",
    "4. [Bonus] Generate confidence intervals using Conformal predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasetsforecast.m4 import M4\n",
    "from statsforecast import StatsForecast\n",
    "import random\n",
    "import os\n",
    "from utils import evaluate_cross_validation, get_best_model_forecast, hour_index\n",
    "\n",
    "random.seed(0)\n",
    "os.environ['NIXTLA_ID_AS_COL'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "await M4.async_download('data', group='Hourly')\n",
    "train_df, *_ = M4.load('data', 'Hourly')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "For the sake of running a faster training, we will randomly pick 4 UIDs only:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = train_df['unique_id'].unique()\n",
    "sample_uids = random.choices(uids, k=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['unique_id'].isin(sample_uids)].reset_index(drop=True)\n",
    "train_df = train_df.groupby('unique_id').tail(7 * 24) \n",
    "train_df['ds'] = train_df['ds'].astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsForecast.plot(train_df, max_insample_length=24 * 14, engine=\"plotly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Baseline definition with StatsForecast\n",
    "\n",
    "As a baseline, we define the following models:\n",
    "\n",
    "- Historical Average: Arithmetic mean\n",
    "- The AutoARIMA model: An implementation of the ARIMA model that uses an automatic process to select the optimal ARIMA (Autoregressive Integrated Moving Average) model parameters for a given time series.\n",
    "\n",
    "Before using those models, we need to adhere to some naming conventions:\n",
    "- [unique_id] for the time series identifier, \n",
    "- [ds] for the date, \n",
    "- [y] for the target variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import (\n",
    "    HistoricAverage,\n",
    "    AutoARIMA\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "HORIZON = 24\n",
    "EXPECTED_SEASONAL_LENGTH = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    HistoricAverage(),\n",
    "    AutoARIMA(season_length=EXPECTED_SEASONAL_LENGTH)\n",
    "]\n",
    "\n",
    "wrapper_models = StatsForecast( \n",
    "    models=models,\n",
    "    freq=1, # Refers to the datestamps in your data. 1 or 'H' for hourly data, 'M' for monthly, etc ... \n",
    "    n_jobs=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "Let's try to forecast the next 24 hours:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = wrapper_models.forecast(df=train_df, h=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsForecast.plot(train_df, forecasts_df, models=[\"HistoricAverage\",\"AutoARIMA\"], engine = 'plotly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "We can also generate confidence intervals using the `level` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIDENCE_LEVEL = 90\n",
    "probabilistic_forecasts_df = wrapper_models.forecast(df=train_df, h=HORIZON, level=[CONFIDENCE_LEVEL])\n",
    "StatsForecast.plot(train_df, probabilistic_forecasts_df, models=[\"AutoARIMA\"], level=[CONFIDENCE_LEVEL], engine = 'plotly')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "We can use the cross-validation function to backtest our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation_df = wrapper_models.cross_validation(\n",
    "    df = train_df,\n",
    "    h = HORIZON,\n",
    "    step_size = HORIZON, # Step size between each window\n",
    "    n_windows = 4,       # Number of windows used for cross validation.\n",
    "    level = [CONFIDENCE_LEVEL]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "crossvalidation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "Let's evaluate our model now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = evaluate_cross_validation(crossvalidation_df, level = [CONFIDENCE_LEVEL])\n",
    "evaluation_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df[[\"metric\", \"AutoARIMA\", \"HistoricAverage\"]].groupby('metric', as_index=False).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df = evaluation_df.groupby(['metric','best_model']).size().sort_values().to_frame()\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "raw",
   "id": "26",
   "metadata": {},
   "source": [
    "You can further explore your results by plotting the unique_ids where a specific model/metric wins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonal_ids = (\n",
    "    evaluation_df\n",
    "    .query('metric == \"coverage_level90\"')\n",
    "    .query('best_model == \"HistoricAverage\"')\n",
    "    .unique_id\n",
    "    .drop_duplicates()\n",
    ")\n",
    "\n",
    "StatsForecast.plot(train_df,crossvalidation_df, unique_ids=seasonal_ids, models=[\"AutoARIMA\",\"HistoricAverage\"], level=[CONFIDENCE_LEVEL], plot_random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "## Beat the baseline !\n",
    "\n",
    "Let's try to beat our baseline. We'll use available  MLForecast tools to compute:\n",
    "- lags, \n",
    "- moving averages (mean, min, max, standard deviation, exponential mean, etc.), \n",
    "- seasonal and moving averages, \n",
    "- seasonal variables, \n",
    "- and manipulate the target variable (BoxCox, differentiation, scaling, etc.).\n",
    "\n",
    "We'll also use a LightGBM model and a very naive custom model that predicts previous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast import MLForecast\n",
    "from mlforecast.lag_transforms import ExpandingMean, RollingMean\n",
    "from mlforecast.target_transforms import Differences\n",
    "import lightgbm as lgb \n",
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "We will start by pre-processing our data to:\n",
    "- Transform our Target values by subtracting the value from the same hour in the previous day (The goal is to remove the strong seasonality on the hour of the day)\n",
    "- Create lag features and rolling averages\n",
    "- Extract date features such as the hour of the day\n",
    "\n",
    "Pre-processing steps can be applied on the data withou training phase using `preprocess` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecaster = MLForecast(\n",
    "    models=[],\n",
    "    freq=1,\n",
    "    target_transforms=[Differences([24])],\n",
    "    lags=[1, 24],\n",
    "    lag_transforms={\n",
    "        1: [ExpandingMean()],\n",
    "        24: [RollingMean(window_size=48)],\n",
    "    },\n",
    "    date_features=[hour_index],\n",
    ")\n",
    "\n",
    "prep_train_df = forecaster.preprocess(train_df)\n",
    "prep_train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "We will now train our model using a Naive Forecasted we define and an LGBM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Naive(BaseEstimator):\n",
    "    def fit(self,X, y):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        return X['lag1']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_params = {\n",
    "    'verbosity': -1,\n",
    "    'num_leaves': 512,\n",
    "}\n",
    "\n",
    "ml_forecaster = MLForecast(\n",
    "    models=[\n",
    "        Naive(),\n",
    "        lgb.LGBMRegressor(**model_params),\n",
    "    ],\n",
    "    freq=1,\n",
    "    target_transforms=[Differences([24])],\n",
    "    lags=[1, 24],\n",
    "    lag_transforms={\n",
    "        1: [ExpandingMean()],\n",
    "        24: [RollingMean(window_size=48)],\n",
    "    },\n",
    "    date_features=[hour_index],\n",
    ")\n",
    "\n",
    "#ml_forecaster.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_forecast = ml_forecaster.predict(h=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsForecast.plot(train_df,ml_forecast)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "# Bonus: Conformal prediction\n",
    "\n",
    "Multi-quantile losses and statistical models can provide prediction intervals, but the problem is that these are uncalibrated, meaning that the actual frequency of observations falling within the interval does not align with the confidence level associated with it. Statistical methods also assume normality. \n",
    "\n",
    "Conformal prediction intervals use cross-validation on a point forecaster model to generate the intervals. This means that no prior probabilities are needed, and the output is well-calibrated. \n",
    "\n",
    "No additional training is needed, and the model is treated as a black box. The approach is compatible with any model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlforecast.utils import PredictionIntervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_forecaster.fit(\n",
    "    train_df,\n",
    "    static_features=[],\n",
    "    prediction_intervals=PredictionIntervals(n_windows=3, h=HORIZON, method=\"conformal_distribution\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_forecast = ml_forecaster.predict(h=HORIZON, level=[CONFIDENCE_LEVEL])\n",
    "StatsForecast.plot(train_df, ml_forecast, level=[CONFIDENCE_LEVEL])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
