{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Nixtla Tutorial\n",
    "The Flash team is excited to share with you a small tutorial on Nixtla.\n",
    "Before jumping into this tutorial, we recommend giving a look to this [README](README.md) in order to get more familiar with Nixtla and its pros/cons ! \n",
    "\n",
    "Now that’s being said, let’s dig into a small example where we will use a hierarchical dataset to forecast the Quarterly Australian Tourism Visits.\n",
    "\n",
    "To do so we'll explore the following features in Nixtla:\n",
    "\n",
    "1. Define statistical models using the StatsForecast Nixtla package\n",
    "2. Reconcile and evaluate the base predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "from datasetsforecast.hierarchical import HierarchicalData\n",
    "from statsforecast import StatsForecast\n",
    "import random\n",
    "\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "## Import data\n",
    "\n",
    "In this example we will use the TourismSmall dataset. \n",
    "The following cell gets:\n",
    "1. `df`: the time series for the different levels in the hierarchy, \n",
    "2. `S`: the summing matrix  which recovers the full dataset from the bottom level hierarchy and,\n",
    "3. `tags`: the indices of each hierarchy denoted by tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, S, tags = HierarchicalData.load(directory='data', group='TourismSmall')\n",
    "\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "test_df  = df.groupby('unique_id').tail(4).sort_values(by='ds')\n",
    "train_df = df.drop(test_df.index).sort_values(by='ds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "When using you're own dataset, you need to adhere to some naming conventions:\n",
    "- [unique_id] for the time series identifier, \n",
    "- [ds] for the date, \n",
    "- [y] for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsForecast.plot(train_df, engine='plotly')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Model definition with StatsForecast\n",
    "\n",
    "We define the following models:\n",
    "\n",
    "- Historical Average: Arthimetic mean\n",
    "- The AutoARIMA model: An implementation of the ARIMA model that uses an automatic process to select the optimal ARIMA (Autoregressive Integrated Moving Average) model parameters for a given time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsforecast.models import (\n",
    "    HistoricAverage,\n",
    "    AutoARIMA\n",
    "    )\n",
    "\n",
    "HORIZON = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    HistoricAverage(),\n",
    "    AutoARIMA(season_length=4)\n",
    "]\n",
    "\n",
    "wrapper_models = StatsForecast( \n",
    "    models=models,\n",
    "    freq='Q', \n",
    "    n_jobs=-1,\n",
    "    fallback_model=HistoricAverage()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "forecasts_df = wrapper_models.forecast(df=train_df, h=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "StatsForecast.plot(train_df, forecasts_df=forecasts_df, models=[\"AutoARIMA\", \"HistoricAverage\"], plot_random=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Prediction reconciliation\n",
    "\n",
    "Large collections of time series organized into structures at different aggregation levels often require their forecasts to follow their aggregation constraints, which poses the challenge of creating novel algorithms capable of coherent forecasts.\n",
    "\n",
    "**HierarchicalForecast** offers a collection of reconciliation methods:\n",
    "- BottomUp: Simple addition to the upper levels.\n",
    "- TopDown: Distributes the top levels forecasts through the hierarchies.\n",
    "- MiddleOut: It anchors the base predictions in a middle level. The levels above the base predictions use the bottom-up approach, while the levels below use a top-down.\n",
    "\n",
    "The full list of reconciliation methods is available [here](https://nixtlaverse.nixtla.io/hierarchicalforecast/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hierarchicalforecast.methods import BottomUp, TopDown, MiddleOut\n",
    "from hierarchicalforecast.core import HierarchicalReconciliation\n",
    "from hierarchicalforecast.evaluation import HierarchicalEvaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = wrapper_models.forecast(h=HORIZON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconcilers = [\n",
    "    BottomUp(),\n",
    "    TopDown(method='forecast_proportions'),\n",
    "    MiddleOut(middle_level='Country/Purpose/State',\n",
    "              top_down_method='forecast_proportions')\n",
    "]\n",
    "\n",
    "hrec = HierarchicalReconciliation(reconcilers=reconcilers)\n",
    "reconciled_predictions = hrec.reconcile(Y_hat_df=predictions, Y_df=train_df, S=S, tags=tags)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "16",
   "metadata": {},
   "source": [
    "The `HierarchicalForecast` package includes the `HierarchicalEvaluation` class to evaluate the different hierarchies and also is capable of compute scaled metrics compared to a benchmark model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse(y, y_hat):\n",
    "    return np.mean((y-y_hat)**2)\n",
    "\n",
    "evaluator = HierarchicalEvaluation(evaluators=[mse])\n",
    "evaluation = evaluator.evaluate(\n",
    "        Y_hat_df=reconciled_predictions, Y_test_df=test_df.set_index('unique_id'),\n",
    "        tags=tags, benchmark='HistoricAverage'\n",
    ")\n",
    "evaluation.filter(like='ARIMA', axis=1).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
